{{TIMESTAMP}} | INIT | Feature activity log created
2025-11-11T09:00:00Z | INFRA | Added docker-compose test stack and env templates to support local and CI execution
2025-11-11T09:05:00Z | TEST | Implemented test helpers (DB, cache) and mock service server for deterministic integration tests
2025-11-11T09:40:00Z | BACKEND | Added access control service with RBAC/ABAC/content policy logic and unit coverage
2025-11-11T09:44:30Z | TEST | Migrated existing unit test suites to ESM, added lightweight Redis mock, and verified `npm run test:unit`
2025-11-11T10:10:00Z | BACKEND | Implemented query processing service with OpenAI integration, context retrieval, caching, and full unit coverage
2025-11-11T10:30:00Z | BACKEND | Added AI integration and personalized assistance services with comprehensive unit tests and mock clients
2025-01-27T14:00:00Z | FRONTEND | Implemented complete Chatbot UI Widget with TailwindCSS, Framer Motion, and React. Created 6 components: ChatWidgetButton (floating bubble), ChatPanel (main container), ChatHeader (greeting + status), ChatMessage (bot/user messages), Recommendations (dynamic suggestions), ChatInput (search bar). Features: Dark Emerald theme, smooth animations, responsive design, mock bot logic, recommendation system with quick actions and cards
2025-01-27T17:00:00Z | FRONTEND | Implemented Proxy Assistant Behavior for Support Mode. Created microserviceProxy service for transparent relay between user and microservices (Assessment/DevLab). Support Mode now acts as proxy: forwards messages verbatim to microservices, returns responses without modification or commentary. Includes metadata (timestamp, session_id, support_mode, user_id, tenant_id). Updated FloatingChatWidget to use proxy behavior in Support Mode while General Mode continues using intelligent responses. Feature F-0017 completed.
2025-01-27T18:00:00Z | BACKEND | Implemented REST API endpoints for chatbot. Created /api/v1/query endpoint for General Chat Mode with OpenAI GPT-3.5-turbo integration. Added proxy endpoints /api/assessment/support and /api/devlab/support for Support Mode. Implemented Query Processing Service with OpenAI embeddings and answer generation. Added recommendations endpoint /api/v1/personalized/recommendations/:userId. Created Query Controller, Microservice Support Controller, and Recommendations Controller. Added CORS middleware, request validation, and error handling. Backend now fully supports frontend chatbot with OpenAI integration.
2025-01-27T18:30:00Z | BACKEND | Fixed Redis to be truly optional. Updated redis.config.js with lazy connection, retry limits, and silent error handling. Redis now stops retrying after 3 attempts to avoid spam. Added REDIS_ENABLED environment variable to completely disable Redis. Updated queryProcessing.service.js to gracefully handle Redis unavailability. Created REDIS_EXPLANATION.md with comprehensive guide on Redis usage, caching benefits, and troubleshooting. Service now works perfectly without Redis (just slower responses without cache).
2025-01-27T19:00:00Z | BACKEND | Fixed CORS configuration to support multiple origins. Updated CORS to support localhost (5173, 3000, 5174) for development and Vercel production URLs via FRONTEND_VERCEL_URL environment variable. Implemented dynamic origin checking function with logging for blocked origins. Added support for credentials, multiple HTTP methods, and custom headers. Created CORS_SETUP.md and CORS_FIX_INSTRUCTIONS.md with detailed setup guides. Backend now supports both local development and production Vercel deployments. Files: index.js, CORS_SETUP.md, CORS_FIX_INSTRUCTIONS.md, updated QUICK_START.md.
2025-11-13T17:53:00Z | DATABASE | Full Database Implementation Complete. Created Prisma migrations for all 11 tables (Tenant, Query, QuerySource, QueryRecommendation, VectorEmbedding, KnowledgeGraphNode, KnowledgeGraphEdge, AccessControlRule, UserProfile, AuditLog, CacheEntry). Added pgvector migration with extension, HNSW index for vector similarity search, GIN indexes for JSONB columns, and database constraints. Implemented Vector Search Service with pgvector cosine similarity search, store/delete embeddings. Implemented Tenant Service for get/create tenant operations. Implemented User Profile Service for user profiles, skill gaps, learning progress. Updated Query Processing Service to fully integrate database: saves all queries with sources/recommendations, uses vector search for RAG retrieval, saves audit logs, uses user profiles for personalization. Updated Railway deployment script to auto-generate Prisma client and deploy migrations. Database now fully functional with Railway + Supabase integration. Files: DATABASE/prisma/migrations/*, BACKEND/src/services/vectorSearch.service.js, BACKEND/src/services/tenant.service.js, BACKEND/src/services/userProfile.service.js, BACKEND/src/services/queryProcessing.service.js, BACKEND/scripts/start-with-migrations.js.
2025-11-13T22:21:00Z | DEPLOYMENT | Fixed Railway + Supabase Migration Deployment. Resolved migration timeout issues by removing pgvector extension creation from migrations (causes "prepared statement already exists" errors with Supabase Transaction Mode Pooler). Updated migrations to assume pgvector is pre-enabled in Supabase SQL Editor. Improved start-with-migrations.js with better timeout handling (10 minutes), maxBuffer (10MB), PRISMA_CLI_QUERY_ENGINE_TYPE=library, and Session Mode Pooler recommendations. All 3 migrations deployed successfully using direct connection (port 5432): tables created, indexes built, constraints applied. Server started successfully. Database fully operational. Files: BACKEND/scripts/start-with-migrations.js, DATABASE/prisma/migrations/20250101000000_init/migration.sql, DATABASE/prisma/migrations/20250101000001_add_pgvector/migration.sql, DATABASE/FINAL_MIGRATION_FIX.md.
2025-01-27T20:00:00Z | BACKEND | Connected Recommendations to Backend API. Created recommendations.service.js with personalized recommendations generation: analyzes user profile (skill gaps, role), query history, popular content, and mode (General/Assessment/DevLab) to generate contextual recommendations. Service includes fallback recommendations if no data available. Updated recommendations.controller.js to use service with query params support (tenant_id, mode, limit). Updated queryProcessing.service.js to generate recommendations after query processing and save to database. Recommendations now saved to QueryRecommendation table with full metadata. Files: BACKEND/src/services/recommendations.service.js, BACKEND/src/controllers/recommendations.controller.js, BACKEND/src/services/queryProcessing.service.js.
2025-01-27T20:00:00Z | FRONTEND | Integrated Frontend with Backend Recommendations API. Updated FloatingChatWidget.jsx to use useGetRecommendationsQuery hook for fetching recommendations from API. Added support for query params (tenant_id, mode, limit). Implemented fallback to client-side recommendations if API unavailable or user anonymous. Updated recommendations display logic to use API recommendations when available, format them for component display. Updated ragApi.js to support query params in getRecommendations endpoint. Recommendations now dynamically loaded from backend based on user profile and context. Files: FRONTEND/src/components/chat/FloatingChatWidget/FloatingChatWidget.jsx, FRONTEND/src/store/api/ragApi.js.
2025-01-27T20:30:00Z | FRONTEND | Fixed Recommendations deployment issue. Fixed RTK Query API call signature - changed from (userId, options) to ({ userId, tenant_id, mode, limit }) object parameter. Fixed useGetRecommendationsQuery hook to pass single object with all parameters. Improved fallback logic: anonymous users always get client-side recommendations, added error handling with recommendationsError check, added useEffect to update recommendations when API data arrives asynchronously, added console.log for debugging. Recommendations now work correctly in production with proper error handling and fallback. Files: FRONTEND/src/store/api/ragApi.js, FRONTEND/src/components/chat/FloatingChatWidget/FloatingChatWidget.jsx.
2025-01-27T21:00:00Z | BACKEND | Integrated AI LEARNER microservice for learning recommendations. Removed "Get Started Guide" from all recommendations (client-side and backend). Created aiLearner.client.js HTTP client to fetch personalized learning recommendations from AI LEARNER microservice. Client includes timeout (5s), error handling, and response transformation. Updated recommendations.service.js to fetch AI LEARNER recommendations in General mode for logged-in users, prioritize them over general recommendations, with graceful fallback if AI LEARNER unavailable. Added axios dependency. Recommendations now personalized per user based on courses, lessons, and skills from AI LEARNER. Files: BACKEND/src/clients/aiLearner.client.js, BACKEND/src/services/recommendations.service.js, BACKEND/package.json.
2025-01-27T21:00:00Z | FRONTEND | Removed "Get Started Guide" from client-side recommendations. Updated recommendations.js to show only "Live Chat" button in General mode fallback. Recommendations now focus on learning content from AI LEARNER when available. Files: FRONTEND/src/utils/recommendations.js.
2025-01-27T21:30:00Z | BACKEND | Migrated AI LEARNER client from HTTP to gRPC. Created grpcClient.util.js with reusable gRPC utilities: loadProto (loads proto files), createGrpcClient (creates gRPC clients), grpcCall (promise wrapper for gRPC calls). Updated aiLearner.client.js to use gRPC PersonalizedService.GetRecommendations RPC call instead of HTTP GET. Client uses personalized.proto (rag.v1.PersonalizedService) for communication. Updated environment variables: AI_LEARNER_GRPC_URL (host:port), AI_LEARNER_PROTO_PATH, AI_LEARNER_SERVICE_NAME. All microservices now communicate via gRPC as per system architecture. Files: BACKEND/src/clients/grpcClient.util.js, BACKEND/src/clients/aiLearner.client.js, env.example.


