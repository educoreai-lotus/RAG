# RAG Service - Batch Flow Analysis Report

**Report Generated:** 2024-12-19  
**Generated By:** Cursor AI Scan  
**Status:** Final

---

## Executive Summary

- **Status:** ‚ö†Ô∏è **Partially Implemented - Not Working**
- **Issue:** Batch sync scheduler is implemented and should be running, but Coordinator is not receiving batch sync requests (no logs in Coordinator)
- **Root Cause:** The batch flow is fully implemented in RAG service, but there may be issues with:
  1. Scheduler not actually running (silent failure)
  2. Coordinator gRPC endpoint not reachable during batch sync
  3. Coordinator not recognizing batch requests (metadata format mismatch)
  4. Environment variables not configured correctly
- **Fix Needed:** 
  1. Verify scheduler is actually running
  2. Add more logging to track batch sync execution
  3. Verify Coordinator receives the gRPC requests
  4. Check if Coordinator recognizes `sync_type: 'batch'` in metadata

---

## 1. Batch Flow Overview

### 1.1 Entry Point

- **Trigger:** Cron scheduler (node-cron)
- **File:** `BACKEND/src/jobs/scheduledSync.js`
- **Function:** `startScheduledSync()` ‚Üí `runBatchSync()` ‚Üí `syncAllServices()`
- **Schedule:** `50 19 * * *` (19:50 UTC daily) - **TEMPORARY for testing** (should be `0 2 * * *` for 2 AM)

### 1.2 Flow Diagram

```
Cron Scheduler (19:50 UTC)
  ‚Üì
startScheduledSync() [scheduledSync.js]
  ‚Üì
runBatchSync() [scheduledSync.js]
  ‚Üì
syncAllServices() [batchSyncService.js]
  ‚Üì
For each service in MICROSERVICES_TO_SYNC:
  ‚Üì
syncService(serviceName) [batchSyncService.js]
  ‚Üì
batchSync({ target_service, sync_type: 'batch' }) [coordinator.client.js]
  ‚Üì
gRPC Route() call to Coordinator
  ‚Üì
Coordinator receives request with metadata:
  - target_service: 'payment-service' (or other)
  - sync_type: 'batch' ‚≠ê CRITICAL
  - page: 1
  - limit: 1000
  ‚Üì
Coordinator routes to target microservice
  ‚Üì
Microservice returns data
  ‚Üì
Coordinator returns response
  ‚Üì
processCoordinatorResponse() [communicationManager.service.js]
  ‚Üì
updateDataStore() [batchSyncService.js] - ‚ö†Ô∏è TODO: Not fully implemented
  ‚Üì
Store in vector DB / embeddings
```

### 1.3 Comparison with Real-time

| Aspect | Real-time | Batch |
|--------|-----------|-------|
| **Trigger** | User HTTP request | Cron scheduler (19:50 UTC) |
| **Endpoint** | `POST /api/v1/query` | N/A (internal scheduler) |
| **Handler** | `queryController.submitQuery()` | `scheduledSync.runBatchSync()` |
| **Coordinator Call** | `routeRequest()` | `batchSync()` |
| **Mode Flag** | `metadata.source: 'rag'` | `metadata.sync_type: 'batch'` ‚≠ê |
| **Query Text** | User's actual query | `sync_{service}_{type}_page_{page}` |
| **Tenant/User** | From request | `tenant_id: 'rag-system'`, `user_id: 'system'` |
| **Timeout** | 30 seconds | 5 minutes (300 seconds) |
| **Purpose** | Answer user query | Sync all data from microservices |

---

## 2. Files Involved

### 2.1 Scheduler Files

- **File:** `BACKEND/src/jobs/scheduledSync.js`
- **Purpose:** Manages cron scheduler for batch sync
- **Status:** ‚úÖ **Implemented**
- **Key Functions:**
  - `startScheduledSync()` - Starts cron job
  - `runBatchSync()` - Executes batch sync
  - `stopScheduledSync()` - Stops cron job
  - `getSchedulerStatus()` - Returns scheduler status

### 2.2 Batch Sync Files

- **File:** `BACKEND/src/services/batchSyncService.js`
- **Purpose:** Handles batch synchronization logic
- **Status:** ‚úÖ **Implemented** (but `updateDataStore()` is TODO)
- **Key Functions:**
  - `syncAllServices()` - Syncs all configured microservices
  - `syncService()` - Syncs a single service with pagination
  - `updateDataStore()` - ‚ö†Ô∏è **TODO: Not fully implemented** (just logs, doesn't actually store)

### 2.3 Coordinator Client Files

- **File:** `BACKEND/src/clients/coordinator.client.js`
- **Purpose:** gRPC client for Coordinator microservice
- **Batch Support:** ‚úÖ **Yes** - Has dedicated `batchSync()` method
- **Key Functions:**
  - `routeRequest()` - Real-time requests
  - `batchSync()` - ‚≠ê **Batch sync requests** (lines 639-867)

### 2.4 Communication Manager

- **File:** `BACKEND/src/communication/communicationManager.service.js`
- **Purpose:** Processes Coordinator responses
- **Status:** ‚úÖ **Implemented**
- **Key Functions:**
  - `processCoordinatorResponse()` - Parses Coordinator response

### 2.5 Main Application

- **File:** `BACKEND/src/index.js`
- **Purpose:** Application entry point
- **Status:** ‚úÖ **Scheduler is started** (line 664)
- **Key Code:**
  ```javascript
  // Start scheduled batch sync job
  try {
    startScheduledSync();
    logger.info('‚úÖ Scheduled batch sync job started');
  } catch (error) {
    logger.warn('‚ö†Ô∏è  Failed to start scheduled batch sync job', {
      error: error.message,
      hint: 'Install node-cron: npm install node-cron',
    });
  }
  ```

---

## 3. Code Analysis

### 3.1 Scheduler Implementation

**File:** `BACKEND/src/jobs/scheduledSync.js`

**Key Code:**
```javascript
// Configuration
const BATCH_SYNC_ENABLED = process.env.BATCH_SYNC_ENABLED !== 'false'; // Default: enabled
const BATCH_SYNC_SCHEDULE = process.env.BATCH_SYNC_SCHEDULE || '50 19 * * *'; // TEMPORARY: 19:50 UTC
const BATCH_SYNC_ON_STARTUP = process.env.BATCH_SYNC_ON_STARTUP === 'true'; // Default: false

// Start scheduler
export function startScheduledSync() {
  if (!BATCH_SYNC_ENABLED) {
    logger.info('[ScheduledSync] Batch sync disabled, not starting scheduler');
    return null;
  }

  if (!cron) {
    logger.warn('[ScheduledSync] node-cron not available, scheduler not started');
    return null;
  }

  // Create scheduled task
  scheduledTask = cron.schedule(BATCH_SYNC_SCHEDULE, async () => {
    try {
      await runBatchSync();
    } catch (error) {
      logger.error('[ScheduledSync] Unhandled error in scheduled task', {
        error: error.message,
      });
    }
  }, {
    scheduled: true,
    timezone: process.env.BATCH_SYNC_TIMEZONE || 'UTC',
  });
}
```

**Issues:**
- ‚úÖ Scheduler is properly implemented
- ‚úÖ node-cron is installed (package.json line 64)
- ‚ö†Ô∏è **Issue:** No verification that scheduler actually started successfully
- ‚ö†Ô∏è **Issue:** If `startScheduledSync()` returns `null`, it's silently ignored in `index.js`
- ‚ö†Ô∏è **Issue:** No health check endpoint to verify scheduler status

### 3.2 Batch Sync Function

**File:** `BACKEND/src/services/batchSyncService.js`

**Key Code:**
```javascript
export async function syncService(serviceName, options = {}) {
  const { syncType = 'batch', since = null } = options;
  
  // Call Coordinator batchSync with required metadata
  const response = await batchSync({
    target_service: serviceName,    // ‚≠ê CRITICAL - tells Coordinator where to route
    sync_type: syncType,             // ‚≠ê CRITICAL - triggers batch mode
    page,
    limit: BATCH_SYNC_LIMIT,
    since,
  });
  
  // Process response
  const processed = processCoordinatorResponse(response);
  
  // Extract data
  const envelopeJson = response.envelope_json;
  // ... parse and store data
}
```

**Issues:**
- ‚úÖ Properly calls `batchSync()` with correct parameters
- ‚úÖ Handles pagination correctly
- ‚ö†Ô∏è **Issue:** `updateDataStore()` is not fully implemented (line 257-295) - just logs, doesn't actually store
- ‚ö†Ô∏è **Issue:** No error recovery if Coordinator returns null
- ‚ö†Ô∏è **Issue:** No retry logic for failed pages

### 3.3 Coordinator Client - Batch Sync Method

**File:** `BACKEND/src/clients/coordinator.client.js`

**Key Code:**
```javascript
export async function batchSync({ 
  target_service, 
  sync_type = 'batch',
  page = 1,
  limit = 1000,
  since = null,
  tenant_id = 'rag-system',
  user_id = 'system'
}) {
  // Validate required parameters
  if (!target_service) {
    logger.error('Invalid batch sync request: target_service is required');
    return null;
  }

  // Create query text for batch sync
  const query_text = `sync_${target_service}_${sync_type}_page_${page}`;

  // Build metadata with batch sync specific fields ‚≠ê CRITICAL
  const metadataMap = {
    target_service: target_service,      // ‚≠ê CRITICAL - tells Coordinator where to route
    sync_type: sync_type,                // ‚≠ê CRITICAL - triggers batch mode
    page: page.toString(),
    limit: limit.toString(),
    requester_service: 'rag-service',
    source: 'rag-batch-sync',
    timestamp: new Date().toISOString(),
  };
  
  // Add envelope_json to metadata
  const envelope = createEnvelope(tenant_id, user_id, query_text, metadataMap);
  metadataMap.envelope_json = JSON.stringify(envelope);
  
  // Build request matching Coordinator's proto structure
  const request = {
    tenant_id: tenant_id || '',
    user_id: user_id || '',
    query_text: query_text,
    metadata: metadataMap  // ‚≠ê Everything in metadata map!
  };

  // Make gRPC call
  const response = await grpcCall(
    client,
    'Route',
    request,
    signedMetadata,
    BATCH_TIMEOUT  // 5 minutes
  );
  
  return response;
}
```

**Issues:**
- ‚úÖ Properly builds batch sync request
- ‚úÖ Includes `sync_type: 'batch'` in metadata ‚≠ê
- ‚úÖ Includes `target_service` in metadata ‚≠ê
- ‚úÖ Uses longer timeout (5 minutes) for batch operations
- ‚ö†Ô∏è **Issue:** If gRPC client is not available, returns `null` silently
- ‚ö†Ô∏è **Issue:** No verification that Coordinator actually received the request
- ‚ö†Ô∏è **Issue:** Error handling might mask the real issue

---

## 4. Findings

### 4.1 What Works ‚úÖ

- ‚úÖ Scheduler is implemented and should be running
- ‚úÖ `node-cron` is installed (package.json)
- ‚úÖ Batch sync service is implemented
- ‚úÖ Coordinator client has `batchSync()` method
- ‚úÖ Batch sync properly sets `sync_type: 'batch'` in metadata
- ‚úÖ Batch sync properly sets `target_service` in metadata
- ‚úÖ Pagination is implemented
- ‚úÖ Error handling per service (doesn't stop all if one fails)
- ‚úÖ Scheduler is started in `index.js` (line 664)

### 4.2 What's Missing ‚ùå

- ‚ùå **Verification that scheduler is actually running** - No health check endpoint
- ‚ùå **Data store update implementation** - `updateDataStore()` is just a placeholder (TODO)
- ‚ùå **Retry logic** - No retry for failed Coordinator calls
- ‚ùå **Monitoring/alerting** - No way to know if batch sync failed
- ‚ùå **Manual trigger endpoint** - No API endpoint to manually trigger batch sync

### 4.3 What's Incomplete ‚ö†Ô∏è

- ‚ö†Ô∏è **Data storage** - `updateDataStore()` doesn't actually store data (line 257-295 in batchSyncService.js)
- ‚ö†Ô∏è **Error recovery** - If Coordinator returns null, sync stops for that service
- ‚ö†Ô∏è **Logging** - Could use more detailed logging to track execution
- ‚ö†Ô∏è **Status reporting** - No way to check if batch sync is currently running

---

## 5. Root Cause Analysis

### 5.1 Why Coordinator Doesn't Receive Requests

**Hypothesis 1: Scheduler is not actually running**
- **Evidence:** 
  - Scheduler is started in `index.js` but if `startScheduledSync()` returns `null`, it's silently ignored
  - No verification that cron job was actually created
  - No health check endpoint to verify scheduler status
- **Likelihood:** **Medium** - Code looks correct, but no verification

**Hypothesis 2: Coordinator gRPC endpoint is not reachable**
- **Evidence:**
  - Real-time flow works (RAG ‚Üí Coordinator ‚Üí Microservice)
  - Batch sync uses same gRPC client
  - But batch sync might be running at different time when network is different
- **Likelihood:** **Low** - Same client, same endpoint

**Hypothesis 3: Coordinator doesn't recognize batch requests**
- **Evidence:**
  - Batch sync sets `sync_type: 'batch'` in metadata
  - Coordinator might not be checking for this field
  - Coordinator might need different metadata format
- **Likelihood:** **High** - This is the most likely issue

**Hypothesis 4: Batch sync is failing silently**
- **Evidence:**
  - If `batchSync()` returns `null`, sync continues to next page
  - Errors might be logged but not visible
  - No monitoring/alerting
- **Likelihood:** **Medium** - Code has error handling, but might mask issues

**Hypothesis 5: Environment variables not configured**
- **Evidence:**
  - `BATCH_SYNC_ENABLED` defaults to `true` (enabled)
  - `BATCH_SYNC_SCHEDULE` defaults to `'50 19 * * *'`
  - But if `BATCH_SYNC_ENABLED=false` in Railway, scheduler won't start
- **Likelihood:** **Low** - Defaults should work

### 5.2 Most Likely Cause

**The most likely cause is Hypothesis 3: Coordinator doesn't recognize batch requests.**

**Reasoning:**
1. Real-time flow works, so gRPC connection is fine
2. Batch sync code is implemented correctly
3. The issue is likely that Coordinator needs to check for `sync_type: 'batch'` in metadata and handle it differently
4. Coordinator might be treating batch requests as regular requests and not routing them correctly

**Additional factors:**
- The scheduler might not be running (Hypothesis 1) - need to verify
- Data storage is not implemented (Hypothesis 4) - but this wouldn't prevent Coordinator from receiving requests

---

## 6. Recommendations

### 6.1 Immediate Fixes

**1. Add Scheduler Health Check Endpoint**
- **What:** Add endpoint to check if scheduler is running
- **Where:** `BACKEND/src/routes/health.routes.js` or new endpoint
- **How:**
  ```javascript
  router.get('/health/batch-sync', (req, res) => {
    const status = getSchedulerStatus();
    res.json({
      enabled: status.enabled,
      isScheduled: status.isScheduled,
      isRunning: status.isRunning,
      cronAvailable: status.cronAvailable,
      schedule: status.schedule,
    });
  });
  ```

**2. Add More Logging to Batch Sync**
- **What:** Add detailed logging at each step
- **Where:** `BACKEND/src/services/batchSyncService.js` and `BACKEND/src/clients/coordinator.client.js`
- **How:**
  ```javascript
  // In batchSyncService.js
  logger.info('[BatchSync] About to call Coordinator batchSync', {
    service: serviceName,
    syncType,
    page,
    limit: BATCH_SYNC_LIMIT,
  });
  
  // In coordinator.client.js
  logger.info('[Coordinator] Batch sync gRPC call starting', {
    target_service,
    sync_type,
    url: COORDINATOR_GRPC_URL,
  });
  ```

**3. Verify Coordinator Receives Batch Requests**
- **What:** Check Coordinator logs for batch sync requests
- **Where:** Coordinator service logs
- **How:** 
  - Look for requests with `sync_type: 'batch'` in metadata
  - Look for requests with `source: 'rag-batch-sync'`
  - Look for requests with `query_text` starting with `sync_`

**4. Implement Data Store Update**
- **What:** Actually store synced data in vector DB
- **Where:** `BACKEND/src/services/batchSyncService.js` - `updateDataStore()` function
- **How:**
  ```javascript
  async function updateDataStore(serviceName, data) {
    // 1. Generate embeddings for all items
    const embeddings = await vectorizer.generateBatch(data.map(item => item.content));
    
    // 2. Store in vector DB
    await storage.storeBatch(data, embeddings, serviceName);
    
    // 3. Update cache
    await cache.update(serviceName, data);
  }
  ```

### 6.2 Implementation Steps

1. **Step 1: Verify Scheduler is Running**
   - Add health check endpoint
   - Check Railway logs for scheduler startup
   - Verify cron job is created

2. **Step 2: Add Detailed Logging**
   - Add logs at each step of batch sync
   - Log when Coordinator is called
   - Log Coordinator response

3. **Step 3: Test Batch Sync Manually**
   - Create manual trigger endpoint
   - Call `runBatchSync()` manually
   - Verify Coordinator receives request

4. **Step 4: Check Coordinator Configuration**
   - Verify Coordinator recognizes `sync_type: 'batch'`
   - Verify Coordinator routes batch requests correctly
   - Check Coordinator logs for batch requests

5. **Step 5: Implement Data Storage**
   - Implement `updateDataStore()` function
   - Store data in vector DB
   - Generate embeddings

### 6.3 Testing Plan

1. **Test 1: Verify Scheduler Starts**
   - Deploy to Railway
   - Check logs for "Scheduled batch sync started"
   - Call health check endpoint

2. **Test 2: Test Manual Batch Sync**
   - Create manual trigger endpoint
   - Call it and verify logs
   - Check Coordinator receives request

3. **Test 3: Test Scheduled Batch Sync**
   - Wait for scheduled time (19:50 UTC)
   - Check logs for batch sync execution
   - Verify Coordinator receives request

4. **Test 4: Verify Data Storage**
   - After batch sync, check vector DB
   - Verify embeddings are created
   - Verify data is searchable

---

## 7. Code Snippets

### 7.1 Current Implementation

**Scheduler Start (index.js):**
```javascript
// Start scheduled batch sync job
try {
  startScheduledSync();
  logger.info('‚úÖ Scheduled batch sync job started');
} catch (error) {
  logger.warn('‚ö†Ô∏è  Failed to start scheduled batch sync job', {
    error: error.message,
    hint: 'Install node-cron: npm install node-cron',
  });
}
```

**Batch Sync Call (batchSyncService.js):**
```javascript
const response = await batchSync({
  target_service: serviceName,
  sync_type: syncType,
  page,
  limit: BATCH_SYNC_LIMIT,
  since,
});
```

**Coordinator Batch Sync (coordinator.client.js):**
```javascript
const metadataMap = {
  target_service: target_service,
  sync_type: sync_type,  // ‚≠ê CRITICAL
  page: page.toString(),
  limit: limit.toString(),
  requester_service: 'rag-service',
  source: 'rag-batch-sync',
};
```

### 7.2 Proposed Fixes

**1. Add Health Check Endpoint:**
```javascript
// In routes/health.routes.js or new file
import { getSchedulerStatus } from '../jobs/scheduledSync.js';

router.get('/health/batch-sync', (req, res) => {
  const status = getSchedulerStatus();
  res.json({
    enabled: status.enabled,
    isScheduled: status.isScheduled,
    isRunning: status.isRunning,
    cronAvailable: status.cronAvailable,
    schedule: status.schedule,
    nextRun: 'Calculating...', // TODO: Implement
  });
});
```

**2. Add Manual Trigger Endpoint:**
```javascript
// In routes/admin.routes.js or new file
import { runBatchSync } from '../jobs/scheduledSync.js';

router.post('/admin/batch-sync/trigger', async (req, res) => {
  try {
    const result = await runBatchSync();
    res.json({
      success: result.success,
      message: 'Batch sync triggered',
      result,
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message,
    });
  }
});
```

**3. Enhanced Logging:**
```javascript
// In batchSyncService.js
logger.info('[BatchSync] Starting sync for service', {
  service: serviceName,
  syncType,
  page,
  limit: BATCH_SYNC_LIMIT,
  coordinatorUrl: process.env.COORDINATOR_GRPC_ENDPOINT,
});

// In coordinator.client.js
logger.info('[Coordinator] Batch sync request prepared', {
  target_service,
  sync_type,
  metadata_keys: Object.keys(metadataMap),
  has_sync_type: !!metadataMap.sync_type,
  coordinator_url: COORDINATOR_GRPC_URL,
});
```

### 7.3 Comparison

| Current | Proposed |
|---------|----------|
| No health check | Add `/health/batch-sync` endpoint |
| Silent failures | Enhanced logging at each step |
| No manual trigger | Add `/admin/batch-sync/trigger` endpoint |
| Data storage TODO | Implement `updateDataStore()` |

---

## 8. Environment Configuration

### 8.1 Required Variables

```bash
# Batch Sync Configuration
BATCH_SYNC_ENABLED=true                    # Default: true (enabled)
BATCH_SYNC_SCHEDULE="50 19 * * *"          # TEMPORARY: 19:50 UTC (should be "0 2 * * *" for 2 AM)
BATCH_SYNC_ON_STARTUP=false                # Default: false
BATCH_SYNC_TIMEZONE="UTC"                   # Default: UTC
BATCH_SYNC_LIMIT=1000                       # Items per page
BATCH_SYNC_SERVICES="payment-service,assessment-service,devlab-service,analytics-service"
BATCH_SYNC_TIMEOUT=300                      # 5 minutes in seconds

# Coordinator Configuration
COORDINATOR_ENABLED=true                    # Default: true
COORDINATOR_GRPC_ENDPOINT=coordinator.railway.internal:50051
COORDINATOR_SIGNATURE_ENABLED=true          # Default: true
RAG_PRIVATE_KEY=<base64-encoded-key>        # Required for signatures
```

### 8.2 Current Values

**Check Railway environment variables:**
- `BATCH_SYNC_ENABLED` - Should be `true` or not set (defaults to `true`)
- `BATCH_SYNC_SCHEDULE` - Should be `"50 19 * * *"` (temporary) or `"0 2 * * *"` (production)
- `COORDINATOR_GRPC_ENDPOINT` - Should be set to Coordinator's gRPC endpoint
- `COORDINATOR_ENABLED` - Should be `true` or not set (defaults to `true`)

---

## 9. Next Steps

1. [ ] **Add health check endpoint** to verify scheduler is running
2. [ ] **Add manual trigger endpoint** to test batch sync manually
3. [ ] **Add enhanced logging** at each step of batch sync
4. [ ] **Verify scheduler is running** in Railway logs
5. [ ] **Test manual batch sync** to verify Coordinator receives requests
6. [ ] **Check Coordinator logs** for batch sync requests
7. [ ] **Verify Coordinator recognizes `sync_type: 'batch'`** in metadata
8. [ ] **Implement `updateDataStore()`** to actually store synced data
9. [ ] **Test scheduled batch sync** at 19:50 UTC
10. [ ] **Monitor logs** for any errors during batch sync

---

## 10. Appendix

### 10.1 Complete File Listings

**Key Files:**
- `BACKEND/src/jobs/scheduledSync.js` - Scheduler (195 lines)
- `BACKEND/src/services/batchSyncService.js` - Batch sync service (387 lines)
- `BACKEND/src/clients/coordinator.client.js` - Coordinator client (931 lines)
- `BACKEND/src/communication/communicationManager.service.js` - Response processor (306 lines)
- `BACKEND/src/index.js` - Application entry (scheduler started at line 664)

### 10.2 Log Examples

**Expected Logs When Batch Sync Runs:**
```
[ScheduledSync] Starting scheduled batch sync
[BatchSync] Starting sync for all services
[BatchSync] Starting sync for service: payment-service
[BatchSync] Fetching page: 1
[Coordinator] Batch sync request via gRPC
[Coordinator] Calling Route RPC for batch sync
[Coordinator] Batch sync response received
[BatchSync] Page sync completed
```

**If Coordinator Doesn't Receive:**
- No logs from Coordinator
- RAG logs show "Batch sync request via gRPC" but no response
- Or gRPC call fails with timeout/connection error

### 10.3 Related Documentation

- Coordinator gRPC proto: `DATABASE/proto/rag/v1/coordinator.proto`
- Real-time flow: `BACKEND/src/services/queryProcessing.service.js`
- Batch handler: `BACKEND/src/handlers/batchHandler.js`

---

## 11. Critical Findings Summary

### ‚úÖ What's Working
1. Scheduler is implemented and should be running
2. Batch sync service is fully implemented
3. Coordinator client has `batchSync()` method
4. Proper metadata is set (`sync_type: 'batch'`, `target_service`)

### ‚ùå What's Not Working
1. **Coordinator is not receiving batch sync requests** (no logs in Coordinator)
2. **Data storage is not implemented** (`updateDataStore()` is TODO)
3. **No way to verify scheduler is running** (no health check)

### ‚ö†Ô∏è What Needs Investigation
1. **Is scheduler actually running?** - Need health check endpoint
2. **Does Coordinator recognize `sync_type: 'batch'`?** - Check Coordinator code
3. **Is gRPC call reaching Coordinator?** - Check network/configuration
4. **Are errors being logged?** - Check Railway logs

### üéØ Most Likely Issue
**Coordinator doesn't recognize batch requests** - Coordinator might not be checking for `sync_type: 'batch'` in metadata, or might need different handling for batch vs real-time requests.

---

**Report Complete** ‚úÖ

